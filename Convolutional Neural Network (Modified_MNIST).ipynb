{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modified MNIST Challenge\n",
    "+ Description\n",
    "+ Dataset\n",
    "+ Imports\n",
    "+ Loading\n",
    "+ Wrangling\n",
    "+ Splitting\n",
    "+ TensorFlow ConvNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "\"For project #3, you are asked to create classifiers to analyze images consisting of two digits and a character. The character may be an 'a' or 'A' (for add), in which case your classifier has to return the sum of the two digits, or an 'm' or 'M' (for multiply), in which case your classifier has to return the product of the two digits. Additionally, a variety of different textures are used in the backgrounds of the images.\n",
    "\n",
    "We provide a set of labeled training data (images and target outputs) as well as a set of unlabeled test data (i.e. images only). You must run your model on the test data and submit the target outputs to Kaggle.\n",
    "\n",
    "You are allowed to use libraries such as theano/sklearn/tensorflow/pytorch for parts 3 and 1 only. For part 2 you must do the full implementation. You can submit any part for kaggle, although the kaggle competition is ranked based on your best submission only and you have a daily limit on number of submissions.\n",
    "\n",
    "Please keep the kaggle teams the same as the teams for the report, and include your kaggle team name in the report so we can grade your performance :)\"\n",
    "\n",
    "Original link of the competition (2017-11-13):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "The following description from the competition page is available:\n",
    "\n",
    "\"The training set (train_x.csv, test_x.csv) consists of 50,000 8bit-greyscale images of size 64x64. There is a unique label for each of the examples, which is the result of the application of operator on the two digits in the image ( result for \"a\"/\"A\" is the sum of two digits and result for \"m\"/\"M\" is the product of two digits ). The total num of unique classes are 40 . ( [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 24, 25, 27, 28, 30, 32, 35, 36, 40, 42, 45, 48, 49, 54, 56, 63, 64, 72, 81] )\n",
    "\n",
    "The test set (test_x.csv) consists of 10000 images of the same format.\n",
    "\n",
    "The .csv file contains the raw uncompressed images pixel values in row major format separated by \",\". Each image is 64 x 64, so each row contains 4096 float values, each containing the a float value which represents the 0-255 greyscale intensity of each pixel.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from datetime import timedelta\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This notebook was developed in Anaconda using Python 3.5.4 and TensorFlow 1.2.1\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "print('This notebook was developed in Anaconda using Python', platform.python_version(), 'and TensorFlow',tf.__version__,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For replayability only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.set_random_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading\n",
    "For this project, we'll be using a modified MNIST dataset obtained from a private Kaggle competition in the course of the third project from McGill's COMP 550 Fall 2017 class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Columns: 4096 entries, 0 to 4095\n",
      "dtypes: float64(4096)\n",
      "memory usage: 1.5 GB\n"
     ]
    }
   ],
   "source": [
    "df_x = pd.read_csv(\"data/Modified_MNIST/train_x.csv\", header=None)\n",
    "df_y = pd.read_csv(\"data/Modified_MNIST/train_y.csv\", header=None)\n",
    "df_x.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is in type float64 which TensorFlow doesn't like so we'll have to deal with this by casting it down to float32."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "Let's visualize the dataset and look at some features. Then we can better decide on the model's architecture and get a sense of batch size for training depending on our available computation power. We will also investigate the various distributions in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>4086</th>\n",
       "      <th>4087</th>\n",
       "      <th>4088</th>\n",
       "      <th>4089</th>\n",
       "      <th>4090</th>\n",
       "      <th>4091</th>\n",
       "      <th>4092</th>\n",
       "      <th>4093</th>\n",
       "      <th>4094</th>\n",
       "      <th>4095</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>107.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>...</td>\n",
       "      <td>164.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>141.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>139.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>...</td>\n",
       "      <td>154.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>148.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>196.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>...</td>\n",
       "      <td>181.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>161.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>137.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>...</td>\n",
       "      <td>50.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>103.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 4096 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0      1      2      3      4      5      6      7      8      9     \\\n",
       "0   34.0   35.0   37.0   34.0   42.0   42.0   40.0   43.0   40.0   38.0   \n",
       "1  107.0   97.0  112.0  122.0  123.0  117.0  132.0  137.0  143.0  141.0   \n",
       "2  139.0  135.0  122.0  178.0  162.0  166.0  160.0  154.0  128.0  149.0   \n",
       "3  196.0  195.0  198.0  209.0  206.0  203.0  205.0  197.0  182.0  172.0   \n",
       "4  137.0  145.0  153.0  161.0  168.0  173.0  175.0  178.0  156.0   18.0   \n",
       "\n",
       "   ...     4086   4087   4088   4089   4090   4091   4092   4093   4094   4095  \n",
       "0  ...     30.0   40.0   50.0   36.0   36.0   82.0   59.0   32.0   36.0   35.0  \n",
       "1  ...    164.0  170.0  170.0  160.0  166.0  161.0  144.0  138.0  136.0  141.0  \n",
       "2  ...    154.0  142.0  147.0  185.0  158.0  150.0   93.0  104.0   96.0  148.0  \n",
       "3  ...    181.0  181.0  180.0  176.0  170.0  173.0  174.0  167.0  163.0  161.0  \n",
       "4  ...     50.0   54.0   61.0   67.0   74.0   80.0   87.0   91.0   99.0  103.0  \n",
       "\n",
       "[5 rows x 4096 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_x.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Dimensions\n",
    "Since these values are useful for shapping our tensor variables, we will save them as constants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IMG_SIZE = 64 # from the description, img is 64x64\n",
    "IMG_SIZE_FLAT = IMG_SIZE**2 # original img data is a 1-D vector\n",
    "IMG_SHAPE = (IMG_SIZE, IMG_SIZE) # tuple to shape our tf vars/placeholders\n",
    "IMG_CHANNELS = 1 # greyscale img\n",
    "NUM_CLASSES = 40 # number of output classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Wrangling\n",
    "We'll now convert our data into a numpy which is easier to work with for machine learning purposes. We will also cast the data to float32 and normalize the features to take values between -1 and 1. Finally, we'll reshape the data into a 4D tensor as defined by the TensorFlow API:\n",
    "\n",
    "[num_samples, img_height, img_width, img_channels]\n",
    "\n",
    "For the targets, we'll one hot encode the targets and create a label dictionnary to recover the original label values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "#data_x = ((df_x.values.astype('float32') / 128) - 1).reshape(-1, IMG_SIZE, IMG_SIZE, IMG_CHANNELS)\n",
    "data_x = df_x.values.astype('float32').reshape(-1, IMG_SIZE, IMG_SIZE, IMG_CHANNELS)\n",
    "data_y = df_y.values.flatten()\n",
    "\n",
    "classes = np.unique(data_y)\n",
    "labels = dict((i,v) for i,v in enumerate(classes))\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_int = label_encoder.fit_transform(data_y).reshape(len(data_y), 1)\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "y_hot = onehot_encoder.fit_transform(y_int).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Visualization\n",
    "We'll define a function to draw the input images. This will be useful to compare the model's classification versus the real label. The function will draw 12 images in a 3x4 grid with the true and predicted labels, if available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_img(images, targets, labels, pred=None):\n",
    "    PLT_ROWS = 3\n",
    "    PLT_COLS = 4\n",
    "    assert len(images) == len(targets) == PLT_ROWS*PLT_COLS\n",
    "    fig, axes = plt.subplots(PLT_ROWS, PLT_COLS)\n",
    "    fig.subplots_adjust(hspace=0.3)\n",
    "    \n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        ax.imshow(images[i].reshape(IMG_SHAPE), cmap='gray', vmin=-1, vmax=1)\n",
    "        \n",
    "        if pred:\n",
    "            xlabel = \"True: {0}, Pred: {1}\".format(labels[targets[i]], labels[pred[i]])\n",
    "        else:\n",
    "            xlabel = \"True: {0}\".format(labels[targets[i]])\n",
    "        ax.set_xlabel(xlabel)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVIAAAD8CAYAAAAltCzFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEZGh/w9JtQXFay63RQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xcfa6c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_img(data_x[0:12], y_int[0:12].flatten(), labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the interesting observation here is that it seems the salient features that compose the symbols of interest are all completly white (pixel rgb value of 255). It may be useful then as a pre-processing step to polarize the input data so to reduce the feature space into binary pixel values. The key would be to select a good threshold value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Metrics\n",
    "Let's now look at some interesting metrics such as class representation. This is useful during data splitting to account for class imbalance, where we could use stratified sampling methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD3CAYAAAAT+Z8iAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x5d6e240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Possible output labels:\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 20 21 24 25 27 28\n",
      " 30 32 35 36 40 42 45 48 49 54 56 63 64 72 81]\n",
      "Highest-count class representation 11.32%\n"
     ]
    }
   ],
   "source": [
    "classes_cnt = [len(data_y[data_y==v]) for _,v in enumerate(classes)]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(np.arange(len(classes)), classes_cnt, align='center')\n",
    "ax.set_xticks(np.arange(len(classes)))\n",
    "ax.set_xticklabels([])\n",
    "plt.show()\n",
    "\n",
    "print('Possible output labels:')\n",
    "print(classes)\n",
    "print('Highest-count class representation %2.2f%%' % (max(classes_cnt)/sum(classes_cnt)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Splitting\n",
    "Let us split the data into a 8:1:1 training, testing, validating set. We will use a stratified sampling scheme to combat the class imbalance noticed above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is a class that wraps our data to get a nice next_batch() functionality. Credits goes to a Stackoverflow comment somewhere on the net."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "\n",
    "    def __init__(self,data):\n",
    "        self._index_in_epoch = 0\n",
    "        self._epochs_completed = 0\n",
    "        self._data = data\n",
    "        self._num_examples = data.shape[0]\n",
    "        pass\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._num_examples\n",
    "\n",
    "    @property\n",
    "    def data(self):\n",
    "        return self._data\n",
    "\n",
    "    def next_batch(self,batch_size=None,shuffle=False):\n",
    "        start = self._index_in_epoch\n",
    "        if not batch_size:\n",
    "            batch_size = self._num_examples\n",
    "            \n",
    "        if shuffle:\n",
    "            idx0 = np.arange(0, self._num_examples)  # get all possible indexes\n",
    "            np.random.shuffle(idx0)  # shuffle indexes\n",
    "            self._data = self.data[idx0]  # get list of `num` random samples\n",
    "\n",
    "        # go to the next batch\n",
    "        if start + batch_size > self._num_examples:\n",
    "            self._epochs_completed += 1\n",
    "            rest_num_examples = self._num_examples - start\n",
    "            data_rest_part = self.data[start:self._num_examples]\n",
    "\n",
    "            start = 0\n",
    "            self._index_in_epoch = batch_size - rest_num_examples #avoid the case where the #sample != integar times of batch_size\n",
    "            end =  self._index_in_epoch  \n",
    "            data_new_part =  self._data[start:end]  \n",
    "            return np.concatenate((data_rest_part, data_new_part), axis=0)\n",
    "        else:\n",
    "            self._index_in_epoch += batch_size\n",
    "            end = self._index_in_epoch\n",
    "            return self._data[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(data_x, y_hot,\n",
    "                                                      test_size=0.2, \n",
    "                                                      stratify=data_y,\n",
    "                                                      random_state=SEED)\n",
    "x_test, x_valid, y_test, y_valid = train_test_split(x_valid, y_valid,\n",
    "                                                    test_size=0.5, \n",
    "                                                    stratify=np.argmax(y_valid, axis=1),\n",
    "                                                    random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test:  40000 Valid:  5000 Test:  5000\n"
     ]
    }
   ],
   "source": [
    "x_train = Dataset(x_train)\n",
    "y_train = Dataset(y_train)\n",
    "x_test = Dataset(x_test)\n",
    "y_test = Dataset(y_test)\n",
    "x_valid = Dataset(x_valid)\n",
    "y_valid = Dataset(y_valid)\n",
    "print('Test: ', len(x_train), 'Valid: ', len(x_valid), 'Test: ', len(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Makinng sure the data is accessible correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVIAAAD8CAYAAAAltCzFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAEotJREFUeJzt3W+MXXWdx/HPZ6bQodtutxWUXWlZgVAxKlkiswppSLTu\nZmGXxj6AJ8YE1PhgFc0G/zwRH7APbKQYK2sMVesqErcsXXVJzCIEkLqZVNO/w59S2obS2cEWKDBT\npp1/330wp/XOdDr/fud37r1z36+EMPecc8/vd76985nf+Z1z73VECAAwd2317gAANDuCFAASEaQA\nkIggBYBEBCkAJCJIASDRgqlW2m7Ze6MiwrnboL75UNt8qO3ZpgzS4onl96bB2dkz9Azqmw+1zYfa\njsepPQAkIkgBIBFBCgCJCFIASESQAkAighQAEhGkAJCIIAWARAQpACQiSAEgEUEKAIkIUgBIRJAC\nQCKCFAASEaQAkIggBYBEBCkAJCJIASARQQoAiQhSAEhEkAJAIoIUABIRpACQiCAFgEQEKQAkIkgB\nIBFBCgCJCFIASESQAkAighQAEhGkAJCIIAWARAQpACQiSAEgEUEKAIkIUgBIRJACQCKCFAASEaQA\nkIggBYBEBCkAJCJIASARQQoAiQhSAEhEkAJAIoIUABIRpACQiCAFgEQEKQAkIkgBIBFBCgCJCFIA\nSESQAkAighQAEhGkAJCIIAWARAQpACQiSAEgEUEKAIkIUgBItGC6DWxX0Y+WRX3zobb5UNvxHBH1\n7gMANDVO7QEgEUEKAIkIUgBIVEqQ2l5ue6ftHbZ7bR+peTztBa3Etttt77a9tWbZ3UUfdhT/fTxn\nH6pUr1rbvtN2t+09tn9q+7xcbdVLHWt7o+3nbb9g+85c7dTTfK9t6RebbN8lqT8i7p1knaPkBm1/\nWdLVkhZFxLpi2d2SjkXExjLbajRV1dr2SkmPS3pfRAzZ/k9JWyPiwTL234gqrO0CSfsk3SDpqKQ/\nSFoXES+Wsf9GNB9rm+PU/sx9EbYvt/2M7Qdsd0taYft4zfpbbW8qfn6n7Ydtb7fdZbtz2obsSyWt\nkbR5qn7MY5XVWmO3yi0qRqKLJP1fycfSaKqq7YclPRsRRyJiUNIWSWszHE8jmXe1rWKOdJWkDRHx\nfkk9kib+tTn9eKOk9RHRKelWST+UJNudtr93jn1/W9K5hutftL3L9v22lyQdQfPIUuuIOFw85+Vi\nv3+MiCezHEHjyvU6frfG6nrakWJZK2n62madvywciIidM9hujaQr7TN3+i61vTAitkvaPnFj22sl\nHY6IvbbXaPwIdKOkuyIibH9T0j2SPpd2GE0hV62XS/pHSZdK6pO01fYtEbGlrI43gSy1haR5UNsq\ngvREzc+jGj8K7piw7bURMTLD/V4naZ3tmyVdIGmJ7c0RcVtEHKvZbpOkh2bb6SaVq9Z/J+mFiDgu\nSbb/S2P1b6UgzVXbHkkrax5fUixrJU1f2ypO7c+MFItJ5NeLeZE2SZ+o2e4xSV848yT76ql2GhFf\njYiVEXGZpE9KejQibiuee3HNpuskdacfRlPIUmtJhyV9xHZHMRr4mKTnyut2U8hV2y5JV9leYXuh\npFsk/aq8bjeFpq9tFUE6cb7ja5IelbRN4+cvPi/peo/dytQt6TPStHOk57LBY7fp7JL0EZ17HnW+\nyVLriPhfjb0Ad0raLWlIxfxUC8lV22FJd2gsJLol/SQi9mfofyNr+tryXnsASMQ7mwAgEUEKAIkI\nUgBIRJACQKIp7yO13bJXoiIi+1tMqW8+1DYfanu2aW/IHxwc1Hnn/emDfvr7+/WjH/1Id9xxR4nd\nK9fPfvYzrV69WitXrpx+40m4wq9RaMW7JqqqL7XNh9pOWDdVQWzH+vXr9ZWvfCVHv0o3NDSk9vZ2\ntbXNbMbi9B+JiQWyXdmItFVfkFWMmqhttjao7QTTJk6zhKgk/fKXv9RLL7004+03bdqkt99+O2OP\nALSCaUekuf7yDA8Pa2RkRAsXLpzxc06dOqW2trZxUw05MCLNi1FTPtQ2n6QR6USjo6Pq7+9P7tS+\nffv01FNPzeo527Zt07PPPpvcNgCUadYj0hMnTujBBx/UZz/72dx9qxtGpHkxasqH2uYzVW3rdmrf\nyAjSvPhlz4fa5lPqqX0j6evr06lTp+rdDQAtrqmDtKurS4cPH653NwC0uNJP7YeGhtTX16fly5en\n9q1uOLXPi9PPfKhtPpWc2g8NDam3t1f79+/X008/XdZuz+mNN97QwMBA9nYAYDqlBelbb72lRx55\nRPv379fatfm/TXb37t3q6Wm1r7YB0Iha8qp9b2+vLrroIi1YMPlHDXBqnxenn/lQ23wa7qp9f3+/\nXn311Xo0LUn63e9+p5MnT9atfQDzS11GpAcPHlRvb6+uv/76Sde/8cYbiggtW7as9LZnghFpXoya\n8qG2+TTdDfl79+5VROiDH/xgZW0eOnRIl156qdra2gjSzPhlz4fa5lPaqf3IyIgOHjxYTq+m8IEP\nfKDSEJWk3//+9xodHa20TQDzw6yC9NSpU9q6dWuuvszYK6+8ojfffHNOzz106JAGBwfPWn7LLbec\n8+ITAEylKd/Z9PLLL+v111+f03Ofe+65SYMUAOZqVkOw9vZ2rVq1KldfZuzaa6+d83NvvPHGEnsC\nAA16saneuNiUFxdE8qG2+TTcfaQAMJ9kC9K+vj7t378/1+4BoGFkC9LBwUEdOnSIMAUw72UL0ne8\n4x265pprdPz48Tnv48iRI+rt7S2xVwBQvqw3Tl544YW68MILZ/28np4eRYTefvvt0u7t3LNnj664\n4gotWrSolP0BwGlzHpGeOnVKO3bsOGt5X1+furu7kzp14MABvfjii7ryyit12WWXJe3rtP7+ft65\nBCCLOQfpwMCAtm3bdtby0dHR5A9cXrFihVauXJm0j4muu+46LV68+Jzru7q6NDIyUmqbAFrDnM+b\nOzo6Jr0xfunSpUk3zEvSe97zninXv/DCC1q6dKne9a53JbVTiy/RAzBXSROQbW31uQ11dHRUZd8Q\nfMMNN5S6PwCtY0ZJODIyoieeeOKs72Kyp38DxWuvvaY9e/bMrXfn8N73vlcXX3xxqfsEgLma8ZDy\n9NXz02Ha0dGhzs7O6Rtoa1N7e7uOHTumvXv3zrGbANC4ZnRq397ertWrV2toaEi7du2aVQPLli3T\nsmXL9Nprr+n888+fUycBoJHxoSWT4ENL8uKDNfKhtvnwoSUAkBFBCgCJCFIASESQAkAighQAEhGk\nAJCIIAWARAQpACQiSAEg0bwJ0ieffFI9PT317gaAFjRvgvSVV17RiRMn6t0NAC1o3rzX/ujRo1q8\neHEp38nEe+3z4v3g+VDbfKaq7bwJ0jIRpHnxy54Ptc2HDy0BgIwIUgBIRJACQKKmCdJt27apu7u7\n3t0AgLM0zcWm/v5+tbe364ILLsjeFheb8uKCSD7UNp+papv0dcxVWrx4cb27AACTappT+zJt3rxZ\nb731Vr27AWCeqOTU/uDBg9q7d6/Wrl2bvK8y9Pf3a9GiRWprm/zvCKf2eXH6mQ+1zafuN+QPDw9r\neHhYHR0dev7553XgwAHddNNNyfvNhSDNi1/2fKhtPqXdkD8wMKD77rtv1h1YsGCBOjo6JElXXHGF\n1qxZM+t9AECjmtWINCI0ODiohQsXVtG3umFEmhejpnyobT6ljUhtz/sQBYDZasmr9gBQphkH6cmT\nJ/Wtb30rZ18q9Z3vfEd9fX317gaAeWDaOdIK+9JQqpojzd1Go6piHi/n/hsZtc1nTrc/AQCmxxwp\nACQiSAEgEUEKAIkIUgBIVHqQ2l5ue6ftHbZ7bR+peZztY/tsL7P9sO3nbD9j+0O52qpaHWv6Y9tH\nbe+YsHyD7edt77L9kO0lufpQpTrW+caini/YvjNXO/U032ub9aq97bsk9UfEvZOsK/V9ZrYfkPQ/\nEfHT4h/mgoiYdzeKVlzT1ZIGJN0fEdfULP+4pMcjYtT2PZIGIuLrZbXbCKqqc/Fa3SfpBklHJf1B\n0rqIeLGM/Tei+Vjb3Kf2Z+65sn15MVJ8wHa3pBW2j9esv9X2puLndxajy+22u2x3TtmIvUxSZ0T8\nVJIiYng+hmihkppKUkQ8Len4JMt/ExGjxcMuSZekHlQDqqrOH5b0bEQciYhBSVskNcbnTeYz72pb\n9RzpKkkbIuL9knokTfzLc/rxRknrI6JT0q2SfihJtjttf2+S/V4m6VXb/16cKnzfdkeeQ2g4uWo6\nU7dL+nXC85tFrjq/W9LLNY+PFMtaSdPXtuqvGjkQETtnsN0aSVfaPv2Xa6nthRGxXdL2SbZfIOlD\nkv45Inba/q6kL0u6u5ReN7ZcNZ2W7W9I6ouILXN5fpOpW51bQNPXtuogPVHz86jGj4gnjiCvjYiR\nGe73iKSXav4xHpb0xbl1senkqumUbH9aYy/sj5axvyaQq849klbWPL6kWNZKmr62VZ/an5kbKSaU\nXy/mSNokfaJmu8ckfeHMk+yrp9ppRPRI+qPty4tFH5P0bGm9bmxZajph/+PeX2z7JklfknRzRAzN\nteNNJleduyRdZXuF7YWSbpH0q/K63RSavrZVB+nEuY+vSXpU0jaNn8v4vKTrbe8uJqA/I007n3eH\npP+wvUvS+yR9s9SeN65sNbW9RdJTGnsxHrb9qWLVfZKWSHq8mJP+bnmH07Cy1DkihjX22n1MUrek\nn0TE/gz9b2RNX1s+tAQAEvHOJgBIRJACQCKCFAASEaQAkGjK+0jNVwpkRX3zobb5UNuzTXtDfite\n1f/TGyfyo775UNt8qO14nNoDQCKCFAASEaQAkIggBYBEBCkAJCJIASARQQoAiQhSAEhEkAJAIoIU\nABIRpACQiCAFgEQEKQAkIkgBIBFBCgCJCFIASESQAkAighQAEhGkAJCIIAWARAQpACQiSAEgEUEK\nAIkIUgBIRJACQCKCFAASEaQAkIggBYBEBCkAJCJIASARQQoAiQhSAEhEkAJAIoIUABIRpACQiCAF\ngEQEKQAkIkgBIBFBCgCJCFIASESQAkAighQAEhGkAJCIIAWARAQpACQiSAEgEUEKAIkIUgBIRJAC\nQCKCFAASEaQAkIggBYBEBCkAJCJIASARQQoAiQhSAEhEkAJAIoIUABIRpACQiCAFgEQLptvAdhX9\naFnUNx9qmw+1Hc8RUe8+AEBT49QeABIRpACQiCAFgETTXmyaCdvLJT0uKST9paQRSceKx50RMVxG\nO5O0+2NJN0o6EhHX1Cy/W9Jtko4Wi74aEb/J0Yeq1avWRdvtknZIOhAR63K1Uy91fB3/i6Tbi3a+\nHxH/lqOdqtWjnrYXSXpC0nmSzpf084j412LdBkk3STopab+k2yOir5R2y77YZPsuSf0Rce8k6xwl\nNmh7taQBSfdPEqTHImJjWW01oiprXezzy5KulrRoPgZprapqa/tqST+W9LeSRiU9Kum2iHipjP03\nigrraUkdETFQ/OHvkvS5iNhh++OSHo+IUdv3SBqIiK+X0W6OU/sz90XYvtz2M7YfsN0taYXt4zXr\nb7W9qfj5nbYftr3ddpftzukaioinJR0/x+pWuD+jslrbvlTSGkmbMxxHI6qqtldJ6oqIwWKE9ltJ\nn8hwPPVWST1jzEDxsENjZ91RrPtNRIwW67okXVLWwVUxR7pK0oaIeL+kHhUHVeP0442S1kdEp6Rb\nJf1Qkmx32v7eHNr9ou1dtu+3vWSOfW82OWv9bUl3lt/lppGrtnsl3WD7L2z/maR/kLQixwE0mGyv\nVdvn2d4pqVfSIxGxc5LNbpf06/TDGFPKHOk0DpzjQCZaI+lK/+lO36W2F0bEdknbZ9nmRkl3RUTY\n/qakeyR9bpb7aEZZam17raTDEbHX9hq1xmh/oiy1jYhnbN+rsbnEPo3NQY+U1ekGli0XImJI0t/Y\nXirpF7ZXRcS+0+ttf0NSX0RsSTyGM6oI0hM1P49q/Ci4Y8K210ZE8osoIo7VPNwk6aHUfTaJXLW+\nTtI62zdLukDSEtubI+K2uXe16WR7HUfEDyT9QJJsr9fYhZD5LnsuRMSbtn8r6e8l7ZMk25/WWDh/\ndLb7m0oVp/ZnRi/FhPLrxRxJm8bPBT0m6QtnnjQ2CT/T/Y8bIdm+uObhOknds+10k8pS64j4akSs\njIjLJH1S0qMtFqJSxtex7YuK//+1pH+S9PNyutzQstTT9kW2/7z4eZHGQvP54vFNkr4k6eZi1Fqa\nKoJ04tzH1zR2ZXKbpJdrln9e0vW2dxcT0J+Rpp0L2SLpKUlX2T5s+1PFqg2299jeJekjap25vWy1\nRtba/qLYdqvGrjD3l9v1hpSrnn8l6alijrRL0n9HxKPFuvskLZH0uO0dtr9b1sHwXnsASMQ7mwAg\nEUEKAIkIUgBIRJACQCKCFAASEaQAkIggBYBEBCkAJPp/HU0ybnjoGj8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x14e431710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_img(x_train.data[0:12], np.argmax(y_train.data[0:12], axis=1), labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GraphDef\n",
    "\n",
    "#### ConvNet\n",
    "Here we define the model's architecture along with all training hyperparameters. We will then test on each model a test set to obtain the best model and finally test against the held-out validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a reset function\n",
    "Funny thing if you modify your nodes and rerun the jupyter block, TensorFlow will keep adding them as new ones to your graph, effectively growing your graph enormous! If you ever hit a GraphDef > 2GB error, you forgot to hit the reset button."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def reset_graph(session=None, seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    global total_iterations\n",
    "    total_iterations = 0\n",
    "    if session:\n",
    "        if not session._closed:\n",
    "            session.close()\n",
    "\n",
    "reset_graph(seed=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "dropout = 0.5\n",
    "batch_size = 250"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=(None, IMG_SIZE, IMG_SIZE, IMG_CHANNELS), name=\"x\")\n",
    "y = tf.placeholder(tf.float32, shape=(None, NUM_CLASSES), name=\"y\")\n",
    "y_class = tf.cast(tf.argmax(y, axis=1), tf.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture\n",
    "We'll define the the convolutional neural network's architecture in layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope('ConvNet'):\n",
    "\n",
    "    weight_init = tf.contrib.layers.xavier_initializer()\n",
    "\n",
    "    # Convolution Layer with 32 filters and a kernel size of 5\n",
    "    conv1 = tf.layers.conv2d(x, filters=16,  kernel_size=[5, 5], padding='Same', kernel_initializer=weight_init, activation=tf.nn.relu)\n",
    "    pool1 = tf.sqrt(tf.layers.average_pooling2d(tf.square(conv1), 2, 2, padding='Same'))\n",
    "    pool12 = tf.sqrt(tf.layers.average_pooling2d(tf.square(pool1), 2, 2, padding='Same'))\n",
    "\n",
    "    conv2 = tf.layers.conv2d(pool1, filters=32, kernel_size=[7,7], padding='Same', kernel_initializer=weight_init, activation=tf.nn.relu)\n",
    "    pool2 = tf.sqrt(tf.layers.average_pooling2d(tf.square(conv2), 2, 2, padding='Same'))\n",
    "\n",
    "    # Flatten the data to a 1-D vector for the fully connected layer\n",
    "    flat1 = tf.contrib.layers.flatten(pool12)\n",
    "    flat2 = tf.contrib.layers.flatten(pool2)\n",
    "    cat1 = tf.concat([flat1, flat2], axis=1)\n",
    "\n",
    "    # Fully connected layer \n",
    "    fc1 = tf.layers.dense(cat1, 20, kernel_initializer=weight_init, activation=tf.nn.relu)\n",
    "\n",
    "    # Apply Dropout \n",
    "    do1 = tf.layers.dropout(fc1, rate=dropout)\n",
    "\n",
    "    logits = tf.layers.dense(do1, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning\n",
    "Defining the evaluation measures and the learning methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\"):\n",
    "    cross = tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(cross, name=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"eval\"):\n",
    "    pred = tf.nn.softmax(logits)\n",
    "    pred_class = tf.argmax(pred, axis=1)\n",
    "    correct = tf.equal(pred_class, y_class)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(session, iterations, batch_size):\n",
    "    global total_iterations\n",
    "    #global train_acc_list\n",
    "    #global valid_acc_list\n",
    "    #global iterations_list\n",
    "    print('Training Model.')\n",
    "    \n",
    "    time_start = time.time()\n",
    "\n",
    "    for batch in range(iterations):\n",
    "        x_batch = x_train.next_batch(batch_size)\n",
    "        y_batch = y_train.next_batch(batch_size)\n",
    "        session.run(training_op, feed_dict={x: x_batch, y: y_batch})   \n",
    "        acc_train = accuracy.eval(session=session, feed_dict={x: x_batch, y: y_batch})\n",
    "        acc_valid = accuracy.eval(session=session, feed_dict={x: x_valid.data, y: y_valid.data})\n",
    "        \n",
    "        #iterations_list += [(total_iterations + batch)]\n",
    "        #train_acc_list += [acc_train]\n",
    "        #valid_acc_list += [acc_valid]\n",
    "        time_now = str(timedelta(seconds=int(round(time.time() - time_start))))\n",
    "        \n",
    "        #print(msg, total_iterations + batch, \"Train accuracy:\", acc_train*100, \"Validation accuracy:\", acc_valid*100)\n",
    "        print('%s %4d\\tTrain accuracy: %2.2f%%\\tValidation accuracy: %2.2f%%' % (time_now, total_iterations + batch, acc_train*100, acc_valid*100))\n",
    "    total_iterations += iterations\n",
    "    print('Training Complete.')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train(sess, iterations=160, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reset_graph(session=sess, seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
